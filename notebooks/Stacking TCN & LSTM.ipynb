{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import style\n",
    "# style.use('ggplot')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_scaled.csv')\n",
    "# df = df.drop(columns=[\"Return\"])\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 Categorical Features:\n",
      "['volatility_bbhi', 'volatility_bbli', 'trend_psar_up_indicator', 'trend_psar_down_indicator', 'ticker', 'exchange', 'sector', 'industry', 'Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
      "13 Continuous Features:\n",
      "['Adj Close', 'volume_obv', 'volume_fi', 'volatility_bbm', 'volatility_bbw', 'trend_macd', 'trend_macd_signal', 'trend_macd_diff', 'momentum_ao', 'momentum_roc', 'Return', 'Dayofyear', 'Elapsed']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1197235 entries, 0 to 1197234\n",
      "Data columns (total 34 columns):\n",
      " #   Column                     Non-Null Count    Dtype         \n",
      "---  ------                     --------------    -----         \n",
      " 0   Date                       1197235 non-null  datetime64[ns]\n",
      " 1   Adj Close                  1197235 non-null  float64       \n",
      " 2   volume_obv                 1197235 non-null  float64       \n",
      " 3   volume_fi                  1197235 non-null  float64       \n",
      " 4   volatility_bbm             1197235 non-null  float64       \n",
      " 5   volatility_bbw             1197235 non-null  float64       \n",
      " 6   volatility_bbhi            1197235 non-null  category      \n",
      " 7   volatility_bbli            1197235 non-null  category      \n",
      " 8   trend_macd                 1197235 non-null  float64       \n",
      " 9   trend_macd_signal          1197235 non-null  float64       \n",
      " 10  trend_macd_diff            1197235 non-null  float64       \n",
      " 11  trend_psar_up_indicator    1197235 non-null  category      \n",
      " 12  trend_psar_down_indicator  1197235 non-null  category      \n",
      " 13  momentum_ao                1197235 non-null  float64       \n",
      " 14  momentum_roc               1197235 non-null  float64       \n",
      " 15  Return                     1197235 non-null  float64       \n",
      " 16  target_price               1197235 non-null  float64       \n",
      " 17  ticker                     1197235 non-null  category      \n",
      " 18  exchange                   1197235 non-null  category      \n",
      " 19  sector                     1197235 non-null  category      \n",
      " 20  industry                   1197235 non-null  category      \n",
      " 21  Year                       1197235 non-null  category      \n",
      " 22  Month                      1197235 non-null  category      \n",
      " 23  Week                       1197235 non-null  category      \n",
      " 24  Day                        1197235 non-null  category      \n",
      " 25  Dayofweek                  1197235 non-null  category      \n",
      " 26  Dayofyear                  1197235 non-null  float64       \n",
      " 27  Is_month_end               1197235 non-null  category      \n",
      " 28  Is_month_start             1197235 non-null  category      \n",
      " 29  Is_quarter_end             1197235 non-null  category      \n",
      " 30  Is_quarter_start           1197235 non-null  category      \n",
      " 31  Is_year_end                1197235 non-null  category      \n",
      " 32  Is_year_start              1197235 non-null  category      \n",
      " 33  Elapsed                    1197235 non-null  float64       \n",
      "dtypes: category(19), datetime64[ns](1), float64(14)\n",
      "memory usage: 159.9 MB\n"
     ]
    }
   ],
   "source": [
    "# def cat_cont_split(df, maxcard=55, omit_vars=['Date', 'Adj Close', 'Return', 'target_price']):\n",
    "def cat_cont_split(df, maxcard=55, omit_vars=['Date', 'target_price']):\n",
    "    \"\"\"Helper function that returns column names of categorical & continuous features from df.\"\"\"\n",
    "    cat_feats, cont_feats = [], []\n",
    "    for col in df:\n",
    "        if col in omit_vars: \n",
    "            continue\n",
    "        if (df[col].dtype==int or df[col].dtype==float) and df[col].unique().shape[0] > maxcard:\n",
    "            cont_feats.append(col)\n",
    "        else:\n",
    "            cat_feats.append(col)\n",
    "    return cat_feats, cont_feats\n",
    "    \n",
    "cat_vars, cont_vars = cat_cont_split(df)\n",
    "print(len(cat_vars), 'Categorical Features:')\n",
    "print(cat_vars)\n",
    "print(len(cont_vars), 'Continuous Features:')\n",
    "print(cont_vars)\n",
    "\n",
    "class Categorifier:\n",
    "    ''' Transform categorical features into category types '''\n",
    "    def apply_train(self, df, cat_vars):\n",
    "        self.cat_vars = cat_vars\n",
    "        self.categories = {}\n",
    "        for v in self.cat_vars:\n",
    "            df.loc[:, v] = df.loc[:, v].astype('category').cat.as_ordered()\n",
    "            self.categories[v] = df[v].cat.categories\n",
    "            \n",
    "    def apply_test(self, df_test):\n",
    "        for v in self.cat_vars:\n",
    "            df_test.loc[:, v] = pd.Categorical(df[v], categories=self.categories[v], ordered=True)\n",
    "\n",
    "cat = Categorifier()\n",
    "cat.apply_train(df, cat_vars)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'target_price'\n",
    "cont_vars = cont_vars\n",
    "cat_sz = [(nc, len(df[nc].cat.categories)+1) for nc in cat_vars]\n",
    "# emb_szs = [(nc, min(50, (nc+1)//2)) for _, nc in cat_sz]\n",
    "emb_szs = [(nc, min(51, round(1.6*nc**0.56))) for _, nc in cat_sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1106055, 128) (28615, 128) (1106055, 1) (28615, 1)\n"
     ]
    }
   ],
   "source": [
    "train_arrs, test_arrs = [], []\n",
    "\n",
    "arr_names = [\"Xhist\", \"Xcat\", \"Xcont\", \"y\", \"dateticker\"]\n",
    "\n",
    "for arr_name in arr_names:\n",
    "    fname = 'data/temporal_data/' + arr_name + \"Train.npy\"\n",
    "    train_arrs.append(np.load(fname, allow_pickle=True))\n",
    "    fname = 'data/temporal_data/' + arr_name + \"Test.npy\"\n",
    "    test_arrs.append(np.load(fname, allow_pickle=True))\n",
    "    \n",
    "XseqTrain, XcatTrain, XcontTrain, yTrain, datetickerTrain = train_arrs\n",
    "XseqTest, XcatTest, XcontTest, yTest, datetickerTest = test_arrs\n",
    "\n",
    "print(XseqTrain.shape, XseqTest.shape, yTrain.shape, yTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stacking_tcn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 64\n",
    "timesteps = 128\n",
    "\n",
    "train_ds = stacking_tcn.HybridDataset(XcatTrain, XcontTrain, XseqTrain, yTrain, timesteps)\n",
    "test_ds = stacking_tcn.HybridDataset(XcatTest, XcontTest, XseqTest, yTest, timesteps)\n",
    "\n",
    "train_dl = DataLoader(train_ds, bs, shuffle=True)\n",
    "val_dl = DataLoader(test_ds, 1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingTCN(\n",
      "  (tcn): TemporalConvNet(\n",
      "    (network): Sequential(\n",
      "      (0): TemporalBlock(\n",
      "        (conv1): Conv1d(1, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(1, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "          (4): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (downsample): Conv1d(1, 32, kernel_size=(1,), stride=(1,))\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): TemporalBlock(\n",
      "        (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "          (4): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (2): TemporalBlock(\n",
      "        (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "          (4): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (3): TemporalBlock(\n",
      "        (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "          (4): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (4): TemporalBlock(\n",
      "        (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "          (4): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(16,), dilation=(16,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (5): TemporalBlock(\n",
      "        (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(32,), dilation=(32,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(32,), dilation=(32,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(32,), dilation=(32,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "          (4): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(32,), dilation=(32,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (6): TemporalBlock(\n",
      "        (conv1): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(64,), dilation=(64,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(64,), dilation=(64,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(64,), dilation=(64,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "          (4): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=(64,), dilation=(64,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (7): TemporalBlock(\n",
      "        (conv1): Conv1d(32, 1, kernel_size=(2,), stride=(1,), padding=(128,), dilation=(128,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (conv2): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=(128,), dilation=(128,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(32, 1, kernel_size=(2,), stride=(1,), padding=(128,), dilation=(128,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "          (4): Conv1d(1, 1, kernel_size=(2,), stride=(1,), padding=(128,), dilation=(128,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (downsample): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(3, 3)\n",
      "    (1): Embedding(3, 3)\n",
      "    (2): Embedding(3, 3)\n",
      "    (3): Embedding(3, 3)\n",
      "    (4): Embedding(486, 51)\n",
      "    (5): Embedding(3, 3)\n",
      "    (6): Embedding(13, 7)\n",
      "    (7): Embedding(105, 22)\n",
      "    (8): Embedding(12, 6)\n",
      "    (9): Embedding(13, 7)\n",
      "    (10): Embedding(54, 15)\n",
      "    (11): Embedding(32, 11)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(3, 3)\n",
      "    (14): Embedding(3, 3)\n",
      "    (15): Embedding(3, 3)\n",
      "    (16): Embedding(3, 3)\n",
      "    (17): Embedding(3, 3)\n",
      "    (18): Embedding(2, 2)\n",
      "  )\n",
      "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Linear(in_features=168, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.001, inplace=False)\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.01, inplace=False)\n",
      "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (ensemb): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cmodel = stacking_tcn.StackingTCN(emb_szs, len(cont_vars), hidden_sizes=[1024, 512], out_size=1,\n",
    "                  emb_dropout = 0.1, dropout_prob = [0.001, .01], use_bn=True,\n",
    "                  cnn_input_size=1, num_kernels=32, kernel_size=2,\n",
    "                  cnn_num_blocks=7, cnn_output_size=1, cnn_dropout=0.2)\n",
    "print(cmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:04<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss=0.15789\n",
      "Epoch 1: val loss=0.05063\n"
     ]
    }
   ],
   "source": [
    "stacking_tcn.train_model(cmodel, val_dl, val_dl, n_epochs=1, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [00:35<00:00, 61.37it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 63.11it/s]\n"
     ]
    }
   ],
   "source": [
    "train_preds, train_targets = stack_tcn.predict(cmodel, train_ds, 512)\n",
    "test_preds, test_targets = stack_tcn.predict(cmodel, test_ds, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stacking_lstm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 64\n",
    "timesteps = 50\n",
    "\n",
    "train_ds = stacking_lstm.HybridDataset(XcatTrain, XcontTrain, XseqTrain, yTrain, timesteps)\n",
    "test_ds = stacking_lstm.HybridDataset(XcatTest, XcontTest, XseqTest, yTest, timesteps)\n",
    "\n",
    "train_dl = DataLoader(train_ds, bs, shuffle=True)\n",
    "val_dl = DataLoader(test_ds, 1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingLSTM(\n",
      "  (rnn): LSTM(1, 30, num_layers=3, batch_first=True)\n",
      "  (fc): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(3, 3)\n",
      "    (1): Embedding(3, 3)\n",
      "    (2): Embedding(3, 3)\n",
      "    (3): Embedding(3, 3)\n",
      "    (4): Embedding(486, 51)\n",
      "    (5): Embedding(3, 3)\n",
      "    (6): Embedding(13, 7)\n",
      "    (7): Embedding(105, 22)\n",
      "    (8): Embedding(12, 6)\n",
      "    (9): Embedding(13, 7)\n",
      "    (10): Embedding(54, 15)\n",
      "    (11): Embedding(32, 11)\n",
      "    (12): Embedding(6, 4)\n",
      "    (13): Embedding(3, 3)\n",
      "    (14): Embedding(3, 3)\n",
      "    (15): Embedding(3, 3)\n",
      "    (16): Embedding(3, 3)\n",
      "    (17): Embedding(3, 3)\n",
      "    (18): Embedding(2, 2)\n",
      "  )\n",
      "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=168, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.001, inplace=False)\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.01, inplace=False)\n",
      "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (ensemb): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rmodel = stacking_lstm.StackingLSTM(emb_szs, len(cont_vars), hidden_sizes=[1024, 512], \n",
    "                emb_dropout = 0.1, dropout_prob = [0.001, .01], use_bn=True,\n",
    "                rnn_input_size=1, rnn_hidden_size=30, rnn_num_layers=3,\n",
    "                rnn_output_size=1, rnn_dropout=0.)\n",
    "print(rmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss=1.63245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:00<00:02, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: val loss=1.18611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: training loss=0.94568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:00<00:02, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: val loss=0.72231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: training loss=0.56579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:00<00:01, 13.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: val loss=0.42188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: training loss=0.32650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:00<00:02, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: val loss=0.24140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: training loss=0.18797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: val loss=0.14143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: training loss=0.11426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:00<00:02, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: val loss=0.09111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: training loss=0.07843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:00<00:02, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: val loss=0.06813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: training loss=0.06268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:00<00:02, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: val loss=0.05848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: training loss=0.05636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/28 [00:00<00:02, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: val loss=0.05479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: training loss=0.05409\n",
      "Epoch 10: val loss=0.05355\n"
     ]
    }
   ],
   "source": [
    "stacking_lstm.train_model(rmodel, val_dl, val_dl, n_epochs=10, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [00:36<00:00, 59.24it/s]\n",
      "100%|██████████| 56/56 [00:00<00:00, 58.38it/s]\n"
     ]
    }
   ],
   "source": [
    "train_preds, train_targets = stacking_lstm.predict(rmodel, train_ds, 512)\n",
    "test_preds, test_targets = stacking_lstm.predict(rmodel, test_ds, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingLSTM(\n",
       "  (rnn): LSTM(1, 30, num_layers=3, batch_first=True)\n",
       "  (fc_rnn): Linear(in_features=30, out_features=1, bias=True)\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(3, 3)\n",
       "    (1): Embedding(3, 3)\n",
       "    (2): Embedding(3, 3)\n",
       "    (3): Embedding(3, 3)\n",
       "    (4): Embedding(486, 51)\n",
       "    (5): Embedding(3, 3)\n",
       "    (6): Embedding(13, 7)\n",
       "    (7): Embedding(105, 22)\n",
       "    (8): Embedding(12, 6)\n",
       "    (9): Embedding(13, 7)\n",
       "    (10): Embedding(54, 15)\n",
       "    (11): Embedding(32, 11)\n",
       "    (12): Embedding(6, 4)\n",
       "    (13): Embedding(3, 3)\n",
       "    (14): Embedding(3, 3)\n",
       "    (15): Embedding(3, 3)\n",
       "    (16): Embedding(3, 3)\n",
       "    (17): Embedding(3, 3)\n",
       "    (18): Embedding(2, 2)\n",
       "  )\n",
       "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=168, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.001, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.01, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (ensemb): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['rnn.weight_ih_l0', 'rnn.weight_hh_l0', 'rnn.bias_ih_l0', 'rnn.bias_hh_l0', 'rnn.weight_ih_l1', 'rnn.weight_hh_l1', 'rnn.bias_ih_l1', 'rnn.bias_hh_l1', 'rnn.weight_ih_l2', 'rnn.weight_hh_l2', 'rnn.bias_ih_l2', 'rnn.bias_hh_l2', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './models/ts_lstm.mod'\n",
    "saved_lstm = torch.load(path)\n",
    "saved_lstm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_statedict(model, saved_modules):\n",
    "    own_state = model.state_dict()\n",
    "    for state_dict in saved_modules:\n",
    "        for name, param in state_dict.items():\n",
    "            if name not in own_state:\n",
    "                print(name)\n",
    "                continue\n",
    "            if isinstance(param, torch.nn.Parameter):\n",
    "                param = param.data\n",
    "            own_state[name].copy_(param)\n",
    "            \n",
    "transfer_statedict(rmodel, [saved_stock2vec, saved_lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingLSTM(\n",
       "  (rnn): LSTM(1, 30, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=30, out_features=1, bias=True)\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(3, 3)\n",
       "    (1): Embedding(3, 3)\n",
       "    (2): Embedding(3, 3)\n",
       "    (3): Embedding(3, 3)\n",
       "    (4): Embedding(486, 51)\n",
       "    (5): Embedding(3, 3)\n",
       "    (6): Embedding(13, 7)\n",
       "    (7): Embedding(105, 22)\n",
       "    (8): Embedding(12, 6)\n",
       "    (9): Embedding(13, 7)\n",
       "    (10): Embedding(54, 15)\n",
       "    (11): Embedding(32, 11)\n",
       "    (12): Embedding(6, 4)\n",
       "    (13): Embedding(3, 3)\n",
       "    (14): Embedding(3, 3)\n",
       "    (15): Embedding(3, 3)\n",
       "    (16): Embedding(3, 3)\n",
       "    (17): Embedding(3, 3)\n",
       "    (18): Embedding(2, 2)\n",
       "  )\n",
       "  (emb_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=168, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.001, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.01, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (ensemb): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f47abaec3b8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmodel.ensemb.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own_state = rmodel.state_dict()\n",
    "# for name, param in saved.items():\n",
    "#     if name not in own_state:\n",
    "#         print(name)\n",
    "#         continue\n",
    "#     if isinstance(param, torch.nn.Parameter):\n",
    "#         param = param.data\n",
    "#     own_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0', 'weight_ih_l1', 'weight_hh_l1', 'bias_ih_l1', 'bias_hh_l1', 'weight_ih_l2', 'weight_hh_l2', 'bias_ih_l2', 'bias_hh_l2'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmodel.rnn.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['rnn.weight_ih_l0', 'rnn.weight_hh_l0', 'rnn.bias_ih_l0', 'rnn.bias_hh_l0', 'rnn.weight_ih_l1', 'rnn.weight_hh_l1', 'rnn.bias_ih_l1', 'rnn.bias_hh_l1', 'rnn.weight_ih_l2', 'rnn.weight_hh_l2', 'rnn.bias_ih_l2', 'rnn.bias_hh_l2', 'fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmodel.state_dict()['embeds.6.weight']\n",
    "# saved_rnn.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own_state = rmodel.state_dict()\n",
    "# for name, param in saved_rnn.items():\n",
    "#     if name not in own_state:\n",
    "#         print(name)\n",
    "#         continue\n",
    "#     if isinstance(param, torch.nn.Parameter):\n",
    "#         param = param.data\n",
    "#     own_state[name].copy_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0',\n",
       "              tensor([[ -1.6964],\n",
       "                      [ -1.1273],\n",
       "                      [ -1.4886],\n",
       "                      [ -1.0371],\n",
       "                      [  1.3325],\n",
       "                      [ -4.8691],\n",
       "                      [ -1.4506],\n",
       "                      [ -3.9815],\n",
       "                      [ -1.9023],\n",
       "                      [ -3.6095],\n",
       "                      [ -1.8696],\n",
       "                      [ -3.1493],\n",
       "                      [  2.1087],\n",
       "                      [ -1.0278],\n",
       "                      [ -2.1997],\n",
       "                      [ -9.7966],\n",
       "                      [ -3.5947],\n",
       "                      [ -2.5994],\n",
       "                      [ -1.5737],\n",
       "                      [  0.2767],\n",
       "                      [ -0.8013],\n",
       "                      [ -3.3813],\n",
       "                      [ -6.0551],\n",
       "                      [ -1.1033],\n",
       "                      [ -4.2144],\n",
       "                      [ -2.0643],\n",
       "                      [ -1.2207],\n",
       "                      [ -5.2666],\n",
       "                      [ -1.2778],\n",
       "                      [ -1.6233],\n",
       "                      [ -0.4260],\n",
       "                      [ -0.4173],\n",
       "                      [ -0.1887],\n",
       "                      [  1.2163],\n",
       "                      [  2.9828],\n",
       "                      [ -1.8936],\n",
       "                      [ -0.0990],\n",
       "                      [ -2.0860],\n",
       "                      [ -0.4761],\n",
       "                      [ -1.1051],\n",
       "                      [ -0.6846],\n",
       "                      [ -0.2775],\n",
       "                      [  4.5174],\n",
       "                      [  1.0010],\n",
       "                      [ -0.1420],\n",
       "                      [  1.0472],\n",
       "                      [ -2.0379],\n",
       "                      [ -0.4953],\n",
       "                      [  0.3325],\n",
       "                      [  1.9650],\n",
       "                      [  0.7180],\n",
       "                      [ -1.2706],\n",
       "                      [-26.0412],\n",
       "                      [  1.5095],\n",
       "                      [ -1.3582],\n",
       "                      [  0.3932],\n",
       "                      [ -0.2209],\n",
       "                      [-11.0948],\n",
       "                      [  1.5128],\n",
       "                      [ -0.5284],\n",
       "                      [  3.0946],\n",
       "                      [ -2.8904],\n",
       "                      [ -0.1153],\n",
       "                      [  2.8399],\n",
       "                      [ -3.7383],\n",
       "                      [  4.1429],\n",
       "                      [  1.2943],\n",
       "                      [ -4.3904],\n",
       "                      [  3.1039],\n",
       "                      [ -3.1452],\n",
       "                      [ -0.1015],\n",
       "                      [  2.6244],\n",
       "                      [ -3.8537],\n",
       "                      [  1.9612],\n",
       "                      [ -1.9977],\n",
       "                      [ -1.9660],\n",
       "                      [  4.1766],\n",
       "                      [  2.4099],\n",
       "                      [ -2.8859],\n",
       "                      [  2.4790],\n",
       "                      [  2.3040],\n",
       "                      [ -3.3937],\n",
       "                      [ -3.8113],\n",
       "                      [  2.5666],\n",
       "                      [ -3.1263],\n",
       "                      [  2.9602],\n",
       "                      [ -0.4467],\n",
       "                      [  0.2049],\n",
       "                      [ -2.7462],\n",
       "                      [ -0.1265],\n",
       "                      [ -1.9399],\n",
       "                      [ -1.4995],\n",
       "                      [ -1.3008],\n",
       "                      [ -0.2390],\n",
       "                      [  2.7990],\n",
       "                      [ -5.0802],\n",
       "                      [ -1.7327],\n",
       "                      [ -4.0292],\n",
       "                      [ -2.1333],\n",
       "                      [ -3.8137],\n",
       "                      [ -1.9981],\n",
       "                      [ -2.2391],\n",
       "                      [  4.5690],\n",
       "                      [ -0.6512],\n",
       "                      [ -1.9323],\n",
       "                      [ -7.4450],\n",
       "                      [ -4.7821],\n",
       "                      [ -2.5329],\n",
       "                      [ -0.5392],\n",
       "                      [  0.7689],\n",
       "                      [ -0.4349],\n",
       "                      [ -3.7062],\n",
       "                      [ -3.4501],\n",
       "                      [  0.7174],\n",
       "                      [ -4.3724],\n",
       "                      [ -0.2411],\n",
       "                      [ -1.0049],\n",
       "                      [ -5.6331],\n",
       "                      [  0.7164],\n",
       "                      [ -1.8068]])),\n",
       "             ('weight_hh_l0',\n",
       "              tensor([[ 1.1233,  0.2837,  0.4973,  ..., -1.5216,  0.6453,  1.5012],\n",
       "                      [ 0.5885,  0.0067,  0.3256,  ...,  0.3888,  0.1563, -0.0399],\n",
       "                      [ 0.0794, -0.1618, -0.0746,  ...,  0.0279,  0.0812, -0.0688],\n",
       "                      ...,\n",
       "                      [ 0.3712,  0.0695, -0.5968,  ...,  1.0494, -2.5249,  1.0631],\n",
       "                      [ 0.9677, -0.2984, -0.5901,  ...,  1.1629, -0.2216, -0.3214],\n",
       "                      [-0.2875, -0.5305, -0.0521,  ..., -0.8211,  0.3097,  0.2415]])),\n",
       "             ('bias_ih_l0',\n",
       "              tensor([-1.4526, -1.7484, -2.4167, -3.0400, -0.8577, -0.9141, -2.5475, -1.2114,\n",
       "                      -1.0056, -1.2870, -2.2569, -1.9366, -2.8447, -3.1122, -1.9616, -2.3237,\n",
       "                       0.9457, -2.2295, -2.0691, -3.2540, -3.2094, -1.4581, -0.6716, -2.6446,\n",
       "                      -1.7465, -2.8988, -2.6076,  0.9915, -3.5540, -2.4589, -1.9869, -1.2861,\n",
       "                      -0.5949, -0.0509, -0.5067, -1.4242, -0.6344,  0.2804, -0.5642, -1.0308,\n",
       "                      -0.7782, -0.5193,  0.2511, -0.5517, -0.6727, -2.7840, -3.4875, -0.2156,\n",
       "                       0.2030, -0.4956, -0.9943, -1.5671,  0.2549, -0.9544, -0.4728, -1.2710,\n",
       "                      -0.7534,  0.3561, -0.5053, -0.7383, -1.1739,  0.9292,  0.1188, -0.5114,\n",
       "                       0.8055, -0.9753, -0.2858,  0.0417, -0.9727,  1.1356, -0.2392, -1.0414,\n",
       "                       0.1703, -0.2707,  0.7028,  1.5190, -1.1666, -0.9311,  0.7716, -0.4690,\n",
       "                      -0.6269,  0.8136,  0.4433, -0.9220, -0.0106, -0.9547, -0.3880,  3.6479,\n",
       "                       0.8165, -0.2893, -1.7869, -2.5026, -2.2638, -2.6154,  2.6354, -0.8026,\n",
       "                      -2.7454, -2.0126, -1.7506, -1.9490, -2.0746, -1.4304, -0.2743, -3.6503,\n",
       "                      -2.1858, -1.5985, -0.5775, -2.1235, -1.2459, -3.7215, -2.6914, -1.2897,\n",
       "                       1.3944, -2.5847, -2.3601, -0.5627, -2.7768,  1.2269, -1.9474, -2.2111])),\n",
       "             ('bias_hh_l0',\n",
       "              tensor([-1.4065e+00, -1.7436e+00, -2.4522e+00, -2.8870e+00, -7.2896e-01,\n",
       "                      -1.0232e+00, -2.4092e+00, -1.1718e+00, -1.1669e+00, -1.1097e+00,\n",
       "                      -2.2884e+00, -2.1906e+00, -2.9004e+00, -3.1805e+00, -2.1346e+00,\n",
       "                      -2.4805e+00,  9.9491e-01, -2.1426e+00, -1.9519e+00, -3.0988e+00,\n",
       "                      -3.1989e+00, -1.3566e+00, -3.8289e-01, -2.8816e+00, -1.5602e+00,\n",
       "                      -2.9764e+00, -2.7280e+00,  1.1663e+00, -3.4492e+00, -2.4202e+00,\n",
       "                      -2.1912e+00, -1.2287e+00, -5.7482e-01, -4.8475e-03, -4.9206e-01,\n",
       "                      -1.1420e+00, -5.5132e-01,  3.4419e-01, -3.5008e-01, -1.1599e+00,\n",
       "                      -7.1756e-01, -5.2723e-01,  8.0956e-02, -4.1636e-01, -5.2069e-01,\n",
       "                      -2.6403e+00, -3.7298e+00, -4.1328e-01,  1.5865e-01, -4.5595e-01,\n",
       "                      -1.1980e+00, -1.5432e+00,  1.5081e-01, -7.1299e-01, -2.7869e-01,\n",
       "                      -1.2000e+00, -8.6160e-01,  2.8577e-01, -3.7881e-01, -7.0463e-01,\n",
       "                      -1.0505e+00,  9.0817e-01,  3.3336e-01, -6.1764e-01,  9.3469e-01,\n",
       "                      -1.1210e+00, -2.5096e-01,  6.8199e-03, -8.9340e-01,  9.8337e-01,\n",
       "                      -9.3049e-02, -9.1016e-01,  3.1077e-01, -3.9369e-01,  7.2272e-01,\n",
       "                       1.6127e+00, -1.2004e+00, -8.4606e-01,  1.0105e+00, -2.7785e-01,\n",
       "                      -7.3418e-01,  8.2291e-01,  7.0760e-01, -9.8625e-01,  2.9591e-03,\n",
       "                      -1.0501e+00, -1.4112e-01,  3.3799e+00,  6.5871e-01, -2.7026e-02,\n",
       "                      -1.4966e+00, -2.3477e+00, -2.1087e+00, -2.8016e+00,  2.5138e+00,\n",
       "                      -9.3279e-01, -2.7565e+00, -2.1109e+00, -1.8762e+00, -2.0506e+00,\n",
       "                      -2.2971e+00, -1.3861e+00, -1.6333e-01, -3.6471e+00, -1.9729e+00,\n",
       "                      -1.5629e+00, -5.8396e-01, -2.0238e+00, -1.5226e+00, -3.8221e+00,\n",
       "                      -2.7861e+00, -1.3599e+00,  1.5546e+00, -2.3657e+00, -2.4296e+00,\n",
       "                      -5.4976e-01, -2.8252e+00,  1.4296e+00, -2.0695e+00, -2.4375e+00])),\n",
       "             ('weight_ih_l1',\n",
       "              tensor([[ 1.1130, -0.3116,  0.1417,  ..., -4.8683, -0.5349,  0.1417],\n",
       "                      [ 0.1487, -0.3416,  0.0520,  ..., -0.6792, -0.2510,  0.0378],\n",
       "                      [-0.0475,  0.1918, -0.0752,  ...,  0.0734,  0.1856,  0.1118],\n",
       "                      ...,\n",
       "                      [ 0.2232, -0.3375, -0.0895,  ...,  3.5994, -0.5156, -0.1954],\n",
       "                      [ 0.0723,  0.0903, -0.1296,  ...,  0.5895,  0.0938, -0.0085],\n",
       "                      [-0.0498, -0.0740, -0.2808,  ..., -0.8930,  0.0550, -0.0072]])),\n",
       "             ('weight_hh_l1',\n",
       "              tensor([[ 2.0400e+00, -3.7674e-01, -7.4332e-01,  ..., -4.5791e-01,\n",
       "                        1.1230e-01,  4.1870e-01],\n",
       "                      [ 1.4777e-01,  3.7959e-02, -1.8138e-02,  ..., -2.6980e-01,\n",
       "                       -1.6829e-01,  1.2678e-01],\n",
       "                      [ 1.9667e-01,  1.2269e-01,  7.5867e-02,  ..., -1.7233e-01,\n",
       "                        8.4784e-02, -7.2289e-02],\n",
       "                      ...,\n",
       "                      [ 3.4565e+00, -5.5258e-01,  3.5074e-01,  ...,  3.5020e-01,\n",
       "                       -3.1372e-01,  1.2088e+00],\n",
       "                      [ 7.2978e-02, -1.1850e-01, -1.8178e-03,  ..., -2.0200e-01,\n",
       "                       -1.3685e-01,  1.0291e-01],\n",
       "                      [-1.9506e-02,  1.1154e-01,  5.9709e-02,  ...,  1.2777e-01,\n",
       "                       -1.2246e-01,  2.5847e-02]])),\n",
       "             ('bias_ih_l1',\n",
       "              tensor([-1.2346, -2.1984, -2.8621, -2.1073, -2.6429, -2.1265, -2.2243, -0.4943,\n",
       "                      -4.2504, -1.2461, -2.8130, -2.0858, -2.5421, -1.5270, -2.1845, -1.7207,\n",
       "                      -2.8974, -1.4083, -2.8118, -3.4464, -2.6636, -2.7853, -4.5706, -2.7106,\n",
       "                      -3.2841, -1.2043, -2.1648, -2.2766, -3.1567, -2.2154, -2.9922, -0.8430,\n",
       "                      -0.7766, -1.5771, -0.5578, -0.6618, -1.9423, -0.7280, -3.1765, -3.6565,\n",
       "                      -1.3187, -2.0489, -0.7142, -2.0403, -1.7066, -3.5810, -1.9576, -2.9360,\n",
       "                       0.1149, -3.1281, -0.6756, -1.6940, -2.1645, -2.0155, -2.7198,  2.0004,\n",
       "                      -0.5686, -2.4708, -1.7551, -1.0880,  0.1851, -0.1216, -0.2687,  0.0546,\n",
       "                      -0.0485, -0.0954, -0.2201,  0.0627, -0.5797,  0.1772,  0.0595, -0.2521,\n",
       "                       0.1651,  0.1160, -0.2149,  1.3086,  0.0293, -0.9084,  0.0652,  0.1616,\n",
       "                       0.1808, -0.1759,  0.3350, -0.0608, -1.2478, -0.0445, -0.0613, -0.0519,\n",
       "                      -0.1628, -0.0907, -0.2088, -2.4028, -2.7014, -2.1668, -2.3233, -2.0537,\n",
       "                      -1.6763, -1.2938, -4.0186,  0.8755, -2.7499, -2.1174, -2.5143, -0.5834,\n",
       "                      -1.9034,  0.0234, -3.1069, -2.7091, -2.6857, -2.5222, -2.6891, -2.4666,\n",
       "                      -3.6028, -2.6929, -2.1858,  4.4148, -2.4867, -2.1088, -3.0867, -2.0896])),\n",
       "             ('bias_hh_l1',\n",
       "              tensor([-1.0523e+00, -2.1544e+00, -3.0029e+00, -2.2650e+00, -2.5451e+00,\n",
       "                      -2.1986e+00, -1.9724e+00, -2.7488e-01, -4.3627e+00, -1.5002e+00,\n",
       "                      -2.9491e+00, -1.8760e+00, -2.4879e+00, -1.4186e+00, -2.0656e+00,\n",
       "                      -1.8715e+00, -2.6631e+00, -1.5652e+00, -2.8817e+00, -3.3707e+00,\n",
       "                      -2.9037e+00, -2.6031e+00, -4.3620e+00, -2.6976e+00, -3.4772e+00,\n",
       "                      -1.1400e+00, -2.2958e+00, -2.1619e+00, -2.9568e+00, -1.9275e+00,\n",
       "                      -2.8508e+00, -9.5173e-01, -1.0256e+00, -1.6086e+00, -5.4222e-01,\n",
       "                      -8.0603e-01, -1.9476e+00, -7.0786e-01, -3.0499e+00, -3.4935e+00,\n",
       "                      -1.0415e+00, -2.1455e+00, -5.0443e-01, -1.8296e+00, -1.7607e+00,\n",
       "                      -3.5979e+00, -1.9802e+00, -3.0322e+00,  1.2694e-01, -3.0346e+00,\n",
       "                      -7.3507e-01, -1.7786e+00, -2.1536e+00, -1.7709e+00, -2.6263e+00,\n",
       "                       1.9251e+00, -6.0457e-01, -2.2842e+00, -1.4456e+00, -9.2812e-01,\n",
       "                       1.3736e-01,  1.6376e-01, -8.9645e-02, -8.0877e-02,  1.3286e-02,\n",
       "                      -9.2995e-02, -1.4312e-01,  4.8812e-02, -3.6132e-01, -3.3270e-02,\n",
       "                       4.8972e-02, -4.2427e-02, -1.5565e-01,  1.2622e-01,  1.2246e-03,\n",
       "                       1.1156e+00,  4.7264e-02, -9.1967e-01,  2.1124e-01,  2.6753e-01,\n",
       "                       1.6573e-01, -2.7358e-01,  2.9283e-01, -9.0278e-02, -1.4602e+00,\n",
       "                      -2.9464e-02, -6.7614e-02,  7.7339e-02,  9.5732e-02,  1.6161e-01,\n",
       "                      -2.5721e-01, -2.1716e+00, -2.6200e+00, -2.1541e+00, -2.2159e+00,\n",
       "                      -2.0772e+00, -1.9593e+00, -1.4169e+00, -4.2859e+00,  8.9283e-01,\n",
       "                      -2.5964e+00, -2.0679e+00, -2.4000e+00, -6.1769e-01, -1.8853e+00,\n",
       "                       8.3416e-03, -2.9137e+00, -2.6028e+00, -2.6530e+00, -2.5090e+00,\n",
       "                      -2.7132e+00, -2.6521e+00, -3.5182e+00, -2.6002e+00, -2.3175e+00,\n",
       "                       4.4088e+00, -2.2967e+00, -2.1037e+00, -3.2630e+00, -1.8554e+00])),\n",
       "             ('weight_ih_l2',\n",
       "              tensor([[ 0.3212,  0.0586,  0.0529,  ...,  0.0572, -0.2603, -0.1321],\n",
       "                      [ 0.1017,  0.1357, -0.0183,  ..., -0.8175,  0.3111, -0.2495],\n",
       "                      [-0.0675,  0.1974,  0.1136,  ..., -0.0630, -0.1374, -0.1404],\n",
       "                      ...,\n",
       "                      [ 0.0638, -0.0326,  0.2682,  ..., -0.5785,  0.1430, -0.0986],\n",
       "                      [ 0.1246,  0.2521,  0.0708,  ...,  0.1492,  0.0409,  0.2694],\n",
       "                      [-0.2306, -0.1636, -0.0831,  ..., -0.2231,  0.1439,  0.1077]])),\n",
       "             ('weight_hh_l2',\n",
       "              tensor([[ 0.0115, -0.1664, -0.1309,  ..., -0.0286, -0.2162,  0.2518],\n",
       "                      [ 0.0935, -0.2286, -0.4646,  ...,  0.0269, -0.5737, -0.0996],\n",
       "                      [-0.0959, -0.0972, -0.0322,  ..., -0.1037,  0.0428,  0.1823],\n",
       "                      ...,\n",
       "                      [ 0.2695, -0.3609,  0.0231,  ...,  0.1480,  0.2546,  0.2698],\n",
       "                      [ 0.1320, -0.1192, -0.0561,  ...,  0.0026,  0.0471, -0.1070],\n",
       "                      [-0.1261, -0.1864, -0.0074,  ...,  0.0354,  0.0181, -0.0918]])),\n",
       "             ('bias_ih_l2',\n",
       "              tensor([-3.2867e+00, -3.0865e+00, -3.1127e+00, -3.1385e+00, -2.8486e+00,\n",
       "                      -2.5936e+00, -2.2824e+00, -1.4735e+00, -2.8635e+00, -2.7910e+00,\n",
       "                      -2.4618e+00, -3.2703e+00, -3.8512e+00, -2.3679e+00, -2.2869e+00,\n",
       "                       9.1433e-01, -2.2757e+00, -3.0117e+00, -3.1190e+00, -2.5862e+00,\n",
       "                      -2.5554e+00, -2.5119e+00, -1.9834e+00, -2.3471e+00, -3.1312e+00,\n",
       "                      -2.5866e+00, -2.7124e+00, -2.3241e+00, -2.3806e+00, -3.0693e+00,\n",
       "                      -1.7222e+00, -1.9652e+00, -7.6444e-01, -1.4326e+00, -4.2319e-01,\n",
       "                      -7.9046e-01, -1.0648e+00, -3.4085e+00, -4.1257e-01, -2.3407e+00,\n",
       "                      -6.3076e-01, -1.3172e+00, -1.8886e+00, -5.8086e-01, -9.3807e-01,\n",
       "                      -4.2461e+00, -9.4455e-01, -5.5931e-01, -1.2158e+00, -1.4156e+00,\n",
       "                      -9.0339e-01, -9.5570e-01, -3.6649e+00, -9.5811e-01, -1.0238e+00,\n",
       "                      -1.5894e+00, -1.0528e+00, -8.3672e-01, -1.7053e+00, -5.0697e-01,\n",
       "                      -5.1577e-01,  1.4017e-01, -5.5305e-02,  2.8619e-01,  1.4780e-01,\n",
       "                       2.0814e-02, -2.4981e-02,  6.1071e-02, -1.6426e-02, -3.1758e-01,\n",
       "                       1.0011e-01, -5.5712e-01, -6.1737e-01, -7.3024e-02, -6.5803e-02,\n",
       "                      -1.0558e-01,  1.6556e-01, -7.7582e-02, -3.0413e-01,  7.5679e-02,\n",
       "                      -4.2476e-02,  2.2847e-04,  2.8652e-02,  6.8046e-02, -1.1709e-01,\n",
       "                      -1.2957e-02,  3.8915e-02,  1.0996e-01, -9.5462e-02, -3.5026e-03,\n",
       "                      -3.2964e+00, -2.8194e+00, -3.2259e+00, -3.1501e+00, -2.7990e+00,\n",
       "                      -2.1642e+00, -2.4390e+00, -1.2767e+00, -2.8666e+00, -3.3004e+00,\n",
       "                      -2.5972e+00, -3.3040e+00, -3.5333e+00, -2.2505e+00, -2.2340e+00,\n",
       "                      -4.4268e-01, -2.3191e+00, -3.1759e+00, -3.1755e+00, -2.5873e+00,\n",
       "                      -2.5867e+00, -2.4150e+00, -1.6072e+00, -2.5467e+00, -3.0123e+00,\n",
       "                      -2.4710e+00, -2.5762e+00, -2.3258e+00, -2.6067e+00, -3.1256e+00])),\n",
       "             ('bias_hh_l2',\n",
       "              tensor([-3.2695, -3.1173, -3.0310, -3.1012, -2.7652, -2.5324, -2.3253, -1.2299,\n",
       "                      -3.0628, -2.5695, -2.6502, -3.2988, -3.9438, -2.2308, -2.4575,  0.8592,\n",
       "                      -2.3656, -2.9936, -3.2288, -2.4309, -2.4910, -2.6582, -1.7350, -2.6700,\n",
       "                      -2.8943, -2.5703, -2.4887, -2.3428, -2.5433, -3.0660, -1.5827, -2.0139,\n",
       "                      -0.7380, -1.2305, -0.4979, -0.8105, -0.7950, -3.2367, -0.3877, -2.4927,\n",
       "                      -0.9476, -1.2393, -2.0747, -0.8068, -0.6929, -4.5083, -0.7465, -0.4202,\n",
       "                      -1.1745, -1.2221, -0.8970, -0.9267, -3.7749, -1.0344, -1.0605, -1.3943,\n",
       "                      -1.1624, -1.0693, -1.8618, -0.3015, -0.6310,  0.2000,  0.1176,  0.3508,\n",
       "                      -0.1022, -0.0329,  0.0335,  0.1556,  0.0964, -0.3152, -0.1307, -0.4302,\n",
       "                      -0.7842,  0.0762,  0.0715, -0.1860, -0.1597, -0.0099, -0.3704, -0.1340,\n",
       "                       0.0667,  0.0183,  0.1960, -0.0339, -0.0575, -0.0777, -0.0991, -0.1229,\n",
       "                      -0.0626, -0.1403, -3.3982, -2.7313, -3.0747, -3.0291, -2.5504, -2.2864,\n",
       "                      -2.3866, -1.4860, -2.9729, -3.2641, -2.3877, -3.0692, -3.6554, -2.4579,\n",
       "                      -2.2731, -0.4734, -2.1927, -3.0570, -3.0174, -2.6793, -2.4125, -2.2376,\n",
       "                      -1.6423, -2.4101, -3.0729, -2.4366, -2.5467, -2.4771, -2.3681, -2.9383]))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmodel.rnn.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('rnn.weight_ih_l0',\n",
       "              tensor([[ -1.6964],\n",
       "                      [ -1.1273],\n",
       "                      [ -1.4886],\n",
       "                      [ -1.0371],\n",
       "                      [  1.3325],\n",
       "                      [ -4.8691],\n",
       "                      [ -1.4506],\n",
       "                      [ -3.9815],\n",
       "                      [ -1.9023],\n",
       "                      [ -3.6095],\n",
       "                      [ -1.8696],\n",
       "                      [ -3.1493],\n",
       "                      [  2.1087],\n",
       "                      [ -1.0278],\n",
       "                      [ -2.1997],\n",
       "                      [ -9.7966],\n",
       "                      [ -3.5947],\n",
       "                      [ -2.5994],\n",
       "                      [ -1.5737],\n",
       "                      [  0.2767],\n",
       "                      [ -0.8013],\n",
       "                      [ -3.3813],\n",
       "                      [ -6.0551],\n",
       "                      [ -1.1033],\n",
       "                      [ -4.2144],\n",
       "                      [ -2.0643],\n",
       "                      [ -1.2207],\n",
       "                      [ -5.2666],\n",
       "                      [ -1.2778],\n",
       "                      [ -1.6233],\n",
       "                      [ -0.4260],\n",
       "                      [ -0.4173],\n",
       "                      [ -0.1887],\n",
       "                      [  1.2163],\n",
       "                      [  2.9828],\n",
       "                      [ -1.8936],\n",
       "                      [ -0.0990],\n",
       "                      [ -2.0860],\n",
       "                      [ -0.4761],\n",
       "                      [ -1.1051],\n",
       "                      [ -0.6846],\n",
       "                      [ -0.2775],\n",
       "                      [  4.5174],\n",
       "                      [  1.0010],\n",
       "                      [ -0.1420],\n",
       "                      [  1.0472],\n",
       "                      [ -2.0379],\n",
       "                      [ -0.4953],\n",
       "                      [  0.3325],\n",
       "                      [  1.9650],\n",
       "                      [  0.7180],\n",
       "                      [ -1.2706],\n",
       "                      [-26.0412],\n",
       "                      [  1.5095],\n",
       "                      [ -1.3582],\n",
       "                      [  0.3932],\n",
       "                      [ -0.2209],\n",
       "                      [-11.0948],\n",
       "                      [  1.5128],\n",
       "                      [ -0.5284],\n",
       "                      [  3.0946],\n",
       "                      [ -2.8904],\n",
       "                      [ -0.1153],\n",
       "                      [  2.8399],\n",
       "                      [ -3.7383],\n",
       "                      [  4.1429],\n",
       "                      [  1.2943],\n",
       "                      [ -4.3904],\n",
       "                      [  3.1039],\n",
       "                      [ -3.1452],\n",
       "                      [ -0.1015],\n",
       "                      [  2.6244],\n",
       "                      [ -3.8537],\n",
       "                      [  1.9612],\n",
       "                      [ -1.9977],\n",
       "                      [ -1.9660],\n",
       "                      [  4.1766],\n",
       "                      [  2.4099],\n",
       "                      [ -2.8859],\n",
       "                      [  2.4790],\n",
       "                      [  2.3040],\n",
       "                      [ -3.3937],\n",
       "                      [ -3.8113],\n",
       "                      [  2.5666],\n",
       "                      [ -3.1263],\n",
       "                      [  2.9602],\n",
       "                      [ -0.4467],\n",
       "                      [  0.2049],\n",
       "                      [ -2.7462],\n",
       "                      [ -0.1265],\n",
       "                      [ -1.9399],\n",
       "                      [ -1.4995],\n",
       "                      [ -1.3008],\n",
       "                      [ -0.2390],\n",
       "                      [  2.7990],\n",
       "                      [ -5.0802],\n",
       "                      [ -1.7327],\n",
       "                      [ -4.0292],\n",
       "                      [ -2.1333],\n",
       "                      [ -3.8137],\n",
       "                      [ -1.9981],\n",
       "                      [ -2.2391],\n",
       "                      [  4.5690],\n",
       "                      [ -0.6512],\n",
       "                      [ -1.9323],\n",
       "                      [ -7.4450],\n",
       "                      [ -4.7821],\n",
       "                      [ -2.5329],\n",
       "                      [ -0.5392],\n",
       "                      [  0.7689],\n",
       "                      [ -0.4349],\n",
       "                      [ -3.7062],\n",
       "                      [ -3.4501],\n",
       "                      [  0.7174],\n",
       "                      [ -4.3724],\n",
       "                      [ -0.2411],\n",
       "                      [ -1.0049],\n",
       "                      [ -5.6331],\n",
       "                      [  0.7164],\n",
       "                      [ -1.8068]], device='cuda:0')),\n",
       "             ('rnn.weight_hh_l0',\n",
       "              tensor([[ 1.1233,  0.2837,  0.4973,  ..., -1.5216,  0.6453,  1.5012],\n",
       "                      [ 0.5885,  0.0067,  0.3256,  ...,  0.3888,  0.1563, -0.0399],\n",
       "                      [ 0.0794, -0.1618, -0.0746,  ...,  0.0279,  0.0812, -0.0688],\n",
       "                      ...,\n",
       "                      [ 0.3712,  0.0695, -0.5968,  ...,  1.0494, -2.5249,  1.0631],\n",
       "                      [ 0.9677, -0.2984, -0.5901,  ...,  1.1629, -0.2216, -0.3214],\n",
       "                      [-0.2875, -0.5305, -0.0521,  ..., -0.8211,  0.3097,  0.2415]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l0',\n",
       "              tensor([-1.4526, -1.7484, -2.4167, -3.0400, -0.8577, -0.9141, -2.5475, -1.2114,\n",
       "                      -1.0056, -1.2870, -2.2569, -1.9366, -2.8447, -3.1122, -1.9616, -2.3237,\n",
       "                       0.9457, -2.2295, -2.0691, -3.2540, -3.2094, -1.4581, -0.6716, -2.6446,\n",
       "                      -1.7465, -2.8988, -2.6076,  0.9915, -3.5540, -2.4589, -1.9869, -1.2861,\n",
       "                      -0.5949, -0.0509, -0.5067, -1.4242, -0.6344,  0.2804, -0.5642, -1.0308,\n",
       "                      -0.7782, -0.5193,  0.2511, -0.5517, -0.6727, -2.7840, -3.4875, -0.2156,\n",
       "                       0.2030, -0.4956, -0.9943, -1.5671,  0.2549, -0.9544, -0.4728, -1.2710,\n",
       "                      -0.7534,  0.3561, -0.5053, -0.7383, -1.1739,  0.9292,  0.1188, -0.5114,\n",
       "                       0.8055, -0.9753, -0.2858,  0.0417, -0.9727,  1.1356, -0.2392, -1.0414,\n",
       "                       0.1703, -0.2707,  0.7028,  1.5190, -1.1666, -0.9311,  0.7716, -0.4690,\n",
       "                      -0.6269,  0.8136,  0.4433, -0.9220, -0.0106, -0.9547, -0.3880,  3.6479,\n",
       "                       0.8165, -0.2893, -1.7869, -2.5026, -2.2638, -2.6154,  2.6354, -0.8026,\n",
       "                      -2.7454, -2.0126, -1.7506, -1.9490, -2.0746, -1.4304, -0.2743, -3.6503,\n",
       "                      -2.1858, -1.5985, -0.5775, -2.1235, -1.2459, -3.7215, -2.6914, -1.2897,\n",
       "                       1.3944, -2.5847, -2.3601, -0.5627, -2.7768,  1.2269, -1.9474, -2.2111],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l0',\n",
       "              tensor([-1.4065e+00, -1.7436e+00, -2.4522e+00, -2.8870e+00, -7.2896e-01,\n",
       "                      -1.0232e+00, -2.4092e+00, -1.1718e+00, -1.1669e+00, -1.1097e+00,\n",
       "                      -2.2884e+00, -2.1906e+00, -2.9004e+00, -3.1805e+00, -2.1346e+00,\n",
       "                      -2.4805e+00,  9.9491e-01, -2.1426e+00, -1.9519e+00, -3.0988e+00,\n",
       "                      -3.1989e+00, -1.3566e+00, -3.8289e-01, -2.8816e+00, -1.5602e+00,\n",
       "                      -2.9764e+00, -2.7280e+00,  1.1663e+00, -3.4492e+00, -2.4202e+00,\n",
       "                      -2.1912e+00, -1.2287e+00, -5.7482e-01, -4.8475e-03, -4.9206e-01,\n",
       "                      -1.1420e+00, -5.5132e-01,  3.4419e-01, -3.5008e-01, -1.1599e+00,\n",
       "                      -7.1756e-01, -5.2723e-01,  8.0956e-02, -4.1636e-01, -5.2069e-01,\n",
       "                      -2.6403e+00, -3.7298e+00, -4.1328e-01,  1.5865e-01, -4.5595e-01,\n",
       "                      -1.1980e+00, -1.5432e+00,  1.5081e-01, -7.1299e-01, -2.7869e-01,\n",
       "                      -1.2000e+00, -8.6160e-01,  2.8577e-01, -3.7881e-01, -7.0463e-01,\n",
       "                      -1.0505e+00,  9.0817e-01,  3.3336e-01, -6.1764e-01,  9.3469e-01,\n",
       "                      -1.1210e+00, -2.5096e-01,  6.8199e-03, -8.9340e-01,  9.8337e-01,\n",
       "                      -9.3049e-02, -9.1016e-01,  3.1077e-01, -3.9369e-01,  7.2272e-01,\n",
       "                       1.6127e+00, -1.2004e+00, -8.4606e-01,  1.0105e+00, -2.7785e-01,\n",
       "                      -7.3418e-01,  8.2291e-01,  7.0760e-01, -9.8625e-01,  2.9591e-03,\n",
       "                      -1.0501e+00, -1.4112e-01,  3.3799e+00,  6.5871e-01, -2.7026e-02,\n",
       "                      -1.4966e+00, -2.3477e+00, -2.1087e+00, -2.8016e+00,  2.5138e+00,\n",
       "                      -9.3279e-01, -2.7565e+00, -2.1109e+00, -1.8762e+00, -2.0506e+00,\n",
       "                      -2.2971e+00, -1.3861e+00, -1.6333e-01, -3.6471e+00, -1.9729e+00,\n",
       "                      -1.5629e+00, -5.8396e-01, -2.0238e+00, -1.5226e+00, -3.8221e+00,\n",
       "                      -2.7861e+00, -1.3599e+00,  1.5546e+00, -2.3657e+00, -2.4296e+00,\n",
       "                      -5.4976e-01, -2.8252e+00,  1.4296e+00, -2.0695e+00, -2.4375e+00],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l1',\n",
       "              tensor([[ 1.1130, -0.3116,  0.1417,  ..., -4.8683, -0.5349,  0.1417],\n",
       "                      [ 0.1487, -0.3416,  0.0520,  ..., -0.6792, -0.2510,  0.0378],\n",
       "                      [-0.0475,  0.1918, -0.0752,  ...,  0.0734,  0.1856,  0.1118],\n",
       "                      ...,\n",
       "                      [ 0.2232, -0.3375, -0.0895,  ...,  3.5994, -0.5156, -0.1954],\n",
       "                      [ 0.0723,  0.0903, -0.1296,  ...,  0.5895,  0.0938, -0.0085],\n",
       "                      [-0.0498, -0.0740, -0.2808,  ..., -0.8930,  0.0550, -0.0072]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l1',\n",
       "              tensor([[ 2.0400e+00, -3.7674e-01, -7.4332e-01,  ..., -4.5791e-01,\n",
       "                        1.1230e-01,  4.1870e-01],\n",
       "                      [ 1.4777e-01,  3.7959e-02, -1.8138e-02,  ..., -2.6980e-01,\n",
       "                       -1.6829e-01,  1.2678e-01],\n",
       "                      [ 1.9667e-01,  1.2269e-01,  7.5867e-02,  ..., -1.7233e-01,\n",
       "                        8.4784e-02, -7.2289e-02],\n",
       "                      ...,\n",
       "                      [ 3.4565e+00, -5.5258e-01,  3.5074e-01,  ...,  3.5020e-01,\n",
       "                       -3.1372e-01,  1.2088e+00],\n",
       "                      [ 7.2978e-02, -1.1850e-01, -1.8178e-03,  ..., -2.0200e-01,\n",
       "                       -1.3685e-01,  1.0291e-01],\n",
       "                      [-1.9506e-02,  1.1154e-01,  5.9709e-02,  ...,  1.2777e-01,\n",
       "                       -1.2246e-01,  2.5847e-02]], device='cuda:0')),\n",
       "             ('rnn.bias_ih_l1',\n",
       "              tensor([-1.2346, -2.1984, -2.8621, -2.1073, -2.6429, -2.1265, -2.2243, -0.4943,\n",
       "                      -4.2504, -1.2461, -2.8130, -2.0858, -2.5421, -1.5270, -2.1845, -1.7207,\n",
       "                      -2.8974, -1.4083, -2.8118, -3.4464, -2.6636, -2.7853, -4.5706, -2.7106,\n",
       "                      -3.2841, -1.2043, -2.1648, -2.2766, -3.1567, -2.2154, -2.9922, -0.8430,\n",
       "                      -0.7766, -1.5771, -0.5578, -0.6618, -1.9423, -0.7280, -3.1765, -3.6565,\n",
       "                      -1.3187, -2.0489, -0.7142, -2.0403, -1.7066, -3.5810, -1.9576, -2.9360,\n",
       "                       0.1149, -3.1281, -0.6756, -1.6940, -2.1645, -2.0155, -2.7198,  2.0004,\n",
       "                      -0.5686, -2.4708, -1.7551, -1.0880,  0.1851, -0.1216, -0.2687,  0.0546,\n",
       "                      -0.0485, -0.0954, -0.2201,  0.0627, -0.5797,  0.1772,  0.0595, -0.2521,\n",
       "                       0.1651,  0.1160, -0.2149,  1.3086,  0.0293, -0.9084,  0.0652,  0.1616,\n",
       "                       0.1808, -0.1759,  0.3350, -0.0608, -1.2478, -0.0445, -0.0613, -0.0519,\n",
       "                      -0.1628, -0.0907, -0.2088, -2.4028, -2.7014, -2.1668, -2.3233, -2.0537,\n",
       "                      -1.6763, -1.2938, -4.0186,  0.8755, -2.7499, -2.1174, -2.5143, -0.5834,\n",
       "                      -1.9034,  0.0234, -3.1069, -2.7091, -2.6857, -2.5222, -2.6891, -2.4666,\n",
       "                      -3.6028, -2.6929, -2.1858,  4.4148, -2.4867, -2.1088, -3.0867, -2.0896],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l1',\n",
       "              tensor([-1.0523e+00, -2.1544e+00, -3.0029e+00, -2.2650e+00, -2.5451e+00,\n",
       "                      -2.1986e+00, -1.9724e+00, -2.7488e-01, -4.3627e+00, -1.5002e+00,\n",
       "                      -2.9491e+00, -1.8760e+00, -2.4879e+00, -1.4186e+00, -2.0656e+00,\n",
       "                      -1.8715e+00, -2.6631e+00, -1.5652e+00, -2.8817e+00, -3.3707e+00,\n",
       "                      -2.9037e+00, -2.6031e+00, -4.3620e+00, -2.6976e+00, -3.4772e+00,\n",
       "                      -1.1400e+00, -2.2958e+00, -2.1619e+00, -2.9568e+00, -1.9275e+00,\n",
       "                      -2.8508e+00, -9.5173e-01, -1.0256e+00, -1.6086e+00, -5.4222e-01,\n",
       "                      -8.0603e-01, -1.9476e+00, -7.0786e-01, -3.0499e+00, -3.4935e+00,\n",
       "                      -1.0415e+00, -2.1455e+00, -5.0443e-01, -1.8296e+00, -1.7607e+00,\n",
       "                      -3.5979e+00, -1.9802e+00, -3.0322e+00,  1.2694e-01, -3.0346e+00,\n",
       "                      -7.3507e-01, -1.7786e+00, -2.1536e+00, -1.7709e+00, -2.6263e+00,\n",
       "                       1.9251e+00, -6.0457e-01, -2.2842e+00, -1.4456e+00, -9.2812e-01,\n",
       "                       1.3736e-01,  1.6376e-01, -8.9645e-02, -8.0877e-02,  1.3286e-02,\n",
       "                      -9.2995e-02, -1.4312e-01,  4.8812e-02, -3.6132e-01, -3.3270e-02,\n",
       "                       4.8972e-02, -4.2427e-02, -1.5565e-01,  1.2622e-01,  1.2246e-03,\n",
       "                       1.1156e+00,  4.7264e-02, -9.1967e-01,  2.1124e-01,  2.6753e-01,\n",
       "                       1.6573e-01, -2.7358e-01,  2.9283e-01, -9.0278e-02, -1.4602e+00,\n",
       "                      -2.9464e-02, -6.7614e-02,  7.7339e-02,  9.5732e-02,  1.6161e-01,\n",
       "                      -2.5721e-01, -2.1716e+00, -2.6200e+00, -2.1541e+00, -2.2159e+00,\n",
       "                      -2.0772e+00, -1.9593e+00, -1.4169e+00, -4.2859e+00,  8.9283e-01,\n",
       "                      -2.5964e+00, -2.0679e+00, -2.4000e+00, -6.1769e-01, -1.8853e+00,\n",
       "                       8.3416e-03, -2.9137e+00, -2.6028e+00, -2.6530e+00, -2.5090e+00,\n",
       "                      -2.7132e+00, -2.6521e+00, -3.5182e+00, -2.6002e+00, -2.3175e+00,\n",
       "                       4.4088e+00, -2.2967e+00, -2.1037e+00, -3.2630e+00, -1.8554e+00],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l2',\n",
       "              tensor([[ 0.3212,  0.0586,  0.0529,  ...,  0.0572, -0.2603, -0.1321],\n",
       "                      [ 0.1017,  0.1357, -0.0183,  ..., -0.8175,  0.3111, -0.2495],\n",
       "                      [-0.0675,  0.1974,  0.1136,  ..., -0.0630, -0.1374, -0.1404],\n",
       "                      ...,\n",
       "                      [ 0.0638, -0.0326,  0.2682,  ..., -0.5785,  0.1430, -0.0986],\n",
       "                      [ 0.1246,  0.2521,  0.0708,  ...,  0.1492,  0.0409,  0.2694],\n",
       "                      [-0.2306, -0.1636, -0.0831,  ..., -0.2231,  0.1439,  0.1077]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l2',\n",
       "              tensor([[ 0.0115, -0.1664, -0.1309,  ..., -0.0286, -0.2162,  0.2518],\n",
       "                      [ 0.0935, -0.2286, -0.4646,  ...,  0.0269, -0.5737, -0.0996],\n",
       "                      [-0.0959, -0.0972, -0.0322,  ..., -0.1037,  0.0428,  0.1823],\n",
       "                      ...,\n",
       "                      [ 0.2695, -0.3609,  0.0231,  ...,  0.1480,  0.2546,  0.2698],\n",
       "                      [ 0.1320, -0.1192, -0.0561,  ...,  0.0026,  0.0471, -0.1070],\n",
       "                      [-0.1261, -0.1864, -0.0074,  ...,  0.0354,  0.0181, -0.0918]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l2',\n",
       "              tensor([-3.2867e+00, -3.0865e+00, -3.1127e+00, -3.1385e+00, -2.8486e+00,\n",
       "                      -2.5936e+00, -2.2824e+00, -1.4735e+00, -2.8635e+00, -2.7910e+00,\n",
       "                      -2.4618e+00, -3.2703e+00, -3.8512e+00, -2.3679e+00, -2.2869e+00,\n",
       "                       9.1433e-01, -2.2757e+00, -3.0117e+00, -3.1190e+00, -2.5862e+00,\n",
       "                      -2.5554e+00, -2.5119e+00, -1.9834e+00, -2.3471e+00, -3.1312e+00,\n",
       "                      -2.5866e+00, -2.7124e+00, -2.3241e+00, -2.3806e+00, -3.0693e+00,\n",
       "                      -1.7222e+00, -1.9652e+00, -7.6444e-01, -1.4326e+00, -4.2319e-01,\n",
       "                      -7.9046e-01, -1.0648e+00, -3.4085e+00, -4.1257e-01, -2.3407e+00,\n",
       "                      -6.3076e-01, -1.3172e+00, -1.8886e+00, -5.8086e-01, -9.3807e-01,\n",
       "                      -4.2461e+00, -9.4455e-01, -5.5931e-01, -1.2158e+00, -1.4156e+00,\n",
       "                      -9.0339e-01, -9.5570e-01, -3.6649e+00, -9.5811e-01, -1.0238e+00,\n",
       "                      -1.5894e+00, -1.0528e+00, -8.3672e-01, -1.7053e+00, -5.0697e-01,\n",
       "                      -5.1577e-01,  1.4017e-01, -5.5305e-02,  2.8619e-01,  1.4780e-01,\n",
       "                       2.0814e-02, -2.4981e-02,  6.1071e-02, -1.6426e-02, -3.1758e-01,\n",
       "                       1.0011e-01, -5.5712e-01, -6.1737e-01, -7.3024e-02, -6.5803e-02,\n",
       "                      -1.0558e-01,  1.6556e-01, -7.7582e-02, -3.0413e-01,  7.5679e-02,\n",
       "                      -4.2476e-02,  2.2847e-04,  2.8652e-02,  6.8046e-02, -1.1709e-01,\n",
       "                      -1.2957e-02,  3.8915e-02,  1.0996e-01, -9.5462e-02, -3.5026e-03,\n",
       "                      -3.2964e+00, -2.8194e+00, -3.2259e+00, -3.1501e+00, -2.7990e+00,\n",
       "                      -2.1642e+00, -2.4390e+00, -1.2767e+00, -2.8666e+00, -3.3004e+00,\n",
       "                      -2.5972e+00, -3.3040e+00, -3.5333e+00, -2.2505e+00, -2.2340e+00,\n",
       "                      -4.4268e-01, -2.3191e+00, -3.1759e+00, -3.1755e+00, -2.5873e+00,\n",
       "                      -2.5867e+00, -2.4150e+00, -1.6072e+00, -2.5467e+00, -3.0123e+00,\n",
       "                      -2.4710e+00, -2.5762e+00, -2.3258e+00, -2.6067e+00, -3.1256e+00],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l2',\n",
       "              tensor([-3.2695, -3.1173, -3.0310, -3.1012, -2.7652, -2.5324, -2.3253, -1.2299,\n",
       "                      -3.0628, -2.5695, -2.6502, -3.2988, -3.9438, -2.2308, -2.4575,  0.8592,\n",
       "                      -2.3656, -2.9936, -3.2288, -2.4309, -2.4910, -2.6582, -1.7350, -2.6700,\n",
       "                      -2.8943, -2.5703, -2.4887, -2.3428, -2.5433, -3.0660, -1.5827, -2.0139,\n",
       "                      -0.7380, -1.2305, -0.4979, -0.8105, -0.7950, -3.2367, -0.3877, -2.4927,\n",
       "                      -0.9476, -1.2393, -2.0747, -0.8068, -0.6929, -4.5083, -0.7465, -0.4202,\n",
       "                      -1.1745, -1.2221, -0.8970, -0.9267, -3.7749, -1.0344, -1.0605, -1.3943,\n",
       "                      -1.1624, -1.0693, -1.8618, -0.3015, -0.6310,  0.2000,  0.1176,  0.3508,\n",
       "                      -0.1022, -0.0329,  0.0335,  0.1556,  0.0964, -0.3152, -0.1307, -0.4302,\n",
       "                      -0.7842,  0.0762,  0.0715, -0.1860, -0.1597, -0.0099, -0.3704, -0.1340,\n",
       "                       0.0667,  0.0183,  0.1960, -0.0339, -0.0575, -0.0777, -0.0991, -0.1229,\n",
       "                      -0.0626, -0.1403, -3.3982, -2.7313, -3.0747, -3.0291, -2.5504, -2.2864,\n",
       "                      -2.3866, -1.4860, -2.9729, -3.2641, -2.3877, -3.0692, -3.6554, -2.4579,\n",
       "                      -2.2731, -0.4734, -2.1927, -3.0570, -3.0174, -2.6793, -2.4125, -2.2376,\n",
       "                      -1.6423, -2.4101, -3.0729, -2.4366, -2.5467, -2.4771, -2.3681, -2.9383],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[-1.6279e+00,  9.7233e-01,  5.5827e-01,  1.4542e+00,  5.3109e-02,\n",
       "                       -1.6026e-03,  2.3111e-04,  3.0411e-01,  1.8048e-01, -1.0590e+00,\n",
       "                       -1.1870e-02, -1.4388e+00, -1.0126e+00,  2.5296e-03, -1.7492e-03,\n",
       "                       -7.5168e-01, -6.8395e-04, -7.5723e-01, -1.4951e+00, -2.4035e-02,\n",
       "                        2.9518e-03,  7.8201e-04,  1.9618e+00,  5.0563e-03, -1.0864e+00,\n",
       "                       -1.4408e-02, -2.8547e-02, -1.0347e-04, -1.0425e-02, -7.2827e-01]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.bias', tensor([0.5878], device='cuda:0'))])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
